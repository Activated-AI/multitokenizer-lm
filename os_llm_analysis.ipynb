{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name           vocab         att             ff\n",
      "gemma2b         14.8%        17.0%           68.2%\n",
      "gemma7b          7.2%        16.0%           76.8%\n",
      "llama8b          7.0%        42.9%           50.1%\n",
      "llama70b         2.0%        40.8%           57.2%\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ArchParams:\n",
    "    name: str\n",
    "    model_dim: int\n",
    "    layers: int\n",
    "    vocab_size: int\n",
    "    ffn_factor: float\n",
    "    sequence_length: int\n",
    "\n",
    "def ff_cost(model_dim, ffn_factor):\n",
    "    return model_dim * 2 * ffn_factor\n",
    "\n",
    "def attention_cost(model_dim, sequence_length):\n",
    "    return (model_dim * 4 + sequence_length )\n",
    "\n",
    "def env_transformer_cost(arch_params: ArchParams) -> dict:\n",
    "    # These calculations are per token, and have a model_dim factored out, which cancels\n",
    "    # in all three branches.\n",
    "    ff = arch_params.layers * ff_cost(arch_params.model_dim, arch_params.ffn_factor)\n",
    "    att = arch_params.layers * attention_cost(arch_params.model_dim, arch_params.sequence_length)    \n",
    "    total = ff + att + arch_params.vocab_size\n",
    "\n",
    "    return {\n",
    "        'ff': ff / total,\n",
    "        'att': att / total,\n",
    "        'vocab': arch_params.vocab_size / total\n",
    "    }\n",
    "\n",
    "arch_params_list = [\n",
    "    ArchParams(\n",
    "        name='gemma2b',\n",
    "        model_dim=2048,\n",
    "        layers=18,\n",
    "        vocab_size=256128,\n",
    "        ffn_factor=16.0,\n",
    "        sequence_length=8192\n",
    "    ),\n",
    "    ArchParams(\n",
    "        name='gemma7b',\n",
    "        model_dim=3072,\n",
    "        layers=28,\n",
    "        vocab_size=256128,\n",
    "        ffn_factor=16.0,\n",
    "        sequence_length=8192\n",
    "    ),\n",
    "    ArchParams(\n",
    "        name='llama8b',\n",
    "        model_dim=4096,\n",
    "        layers=32,\n",
    "        vocab_size=128000,\n",
    "        ffn_factor=3.5,\n",
    "        sequence_length=8192\n",
    "    ),\n",
    "    ArchParams(\n",
    "        name='llama70b',\n",
    "        model_dim=8192,\n",
    "        layers=64,\n",
    "        vocab_size=128000,\n",
    "        ffn_factor=3.5,\n",
    "        sequence_length=8192\n",
    "    ),\n",
    "]\n",
    "print(f\"{'name'.ljust(10)}{'vocab':>10}{'att':>12}{'ff':>15}\")\n",
    "for param in arch_params_list:\n",
    "    costs = env_transformer_cost(param)\n",
    "    print(f\"{param.name.ljust(10)} {costs['vocab']:>10.1%} {costs['att']:>12.1%} {costs['ff']:>15.1%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac41230f5c7d4245a59927afb372aefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1635a87cc90d48719e5130bf9c7329de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21dcceb508774684ae7bedc7d6fe995d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ccab3ab07bc4f2b80b4888ea5042ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tok = AutoTokenizer.from_pretrained('NousResearch/gemma-2b-it-tokenizer')\n",
    "# v = tok.get_vocab()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
